{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1944cd-23fc-4cee-9ebe-6947c17a258e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#change current working dictonary, this file should in PathomicFusion folder \n",
    "import os\n",
    "os.chdir(\"PathomicFusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4205cdf-7a9b-4615-b1c9-53a19f46342f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "!ls\n",
    "!ls data\n",
    "!ls data/TCGA_GBMLGG\n",
    "!ls data/TCGA_GBMLGG/gbmlgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e219b-d58e-4b43-84bb-d2558b61a91f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "split_path = \"data/TCGA_GBMLGG/splits/gbmlgg15cv_all_st_patches_512_0_0_0.pkl\"  \n",
    "\n",
    "with open(split_path, \"rb\") as f:\n",
    "    splits = pickle.load(f)\n",
    "\n",
    "\n",
    "print(type(splits))\n",
    "print(list(splits.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e43a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e9d7b8-9687-4705-84f4-0ffd29152169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "packages = {\n",
    "    \"torch\": \"torch\",\n",
    "    \"torchvision\": \"torchvision\",\n",
    "    \"scikit-learn\": \"sklearn\",\n",
    "    \"opencv-python\": \"cv2\",\n",
    "    \"tensorboard\": \"tensorboard\",\n",
    "    \"scipy\": \"scipy\",\n",
    "    \"lifelines\": \"lifelines\",\n",
    "}\n",
    "\n",
    "for pip_name, import_name in packages.items():\n",
    "    try:\n",
    "        mod = importlib.import_module(import_name)\n",
    "        version = getattr(mod, \"__version__\", \"no __version__ attr\")\n",
    "        print(f\"[OK] {pip_name:15s}  (import as '{import_name}')  version: {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"[MISSING] {pip_name:15s}  (import as '{import_name}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c8031-b18a-4356-b77e-590d0d8d9755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m pip install\\\n",
    "    opencv-python \\\n",
    "    tensorboard \\\n",
    "    lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e391a4ae-4e9a-42f6-ad75-12ea598a36fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!\"{sys.executable}\" -m pip install tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026c2ae-5d92-4aca-b46e-ba635b73cd98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!\"{sys.executable}\" -m pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4501847-8393-4507-8a87-fce938c72681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!\"{sys.executable}\" -m pip install \\\n",
    "    imbalanced-learn \\\n",
    "    pillow \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd93a0-38c7-414e-bef2-5e4463dc12b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!\"{sys.executable}\" -m pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8308f7-4601-47af-a6c8-5ba8d4ff83de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# small test on omic alone \n",
    "#changes make in train_cv.py: \n",
    "#data_cv_path =  and in part 3 Sets-Up Main Loop of train_cv.py(change the code \n",
    "#(for k, data in data_cv_splits.items():) to \n",
    "# (all_splits = list(data_cv_splits.items()for k, data in all_splits[:1]: )\n",
    "!\"{sys.executable}\" train_cv.py \\\n",
    "  --dataroot ./data/TCGA_GBMLGG \\\n",
    "  --checkpoints_dir ./checkpoints/TCGA_GBMLGG \\\n",
    "  --exp_name grad_15 \\\n",
    "  --task grad \\\n",
    "  --mode omic \\\n",
    "  --model_name omic \\\n",
    "  --niter 3 \\\n",
    "  --niter_decay 0 \\\n",
    "  --batch_size 64 \\\n",
    "  --lr 0.002 \\\n",
    "  --reg_type all \\\n",
    "  --init_type max \\\n",
    "  --weight_decay 5e-4 \\\n",
    "  --act LSM \\\n",
    "  --label_dim 3 \\\n",
    "  --gpu_ids -1 \\\n",
    "  --use_rnaseq 0 \\\n",
    "  --verbose 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1bb0c5-ccfd-4fa2-abd1-8bdbed68940f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# small test on pathomic \n",
    "#changes make in train_cv.py: \n",
    "#data_cv_path =  and in part 3 Sets-Up Main Loop of train_cv.py(change the code \n",
    "#(for k, data in data_cv_splits.items():) to \n",
    "# (all_splits = list(data_cv_splits.items()for k, data in all_splits[:1]: )\n",
    "\n",
    "\n",
    "\n",
    "!\"{sys.executable}\" train_cv.py \\\n",
    "    --exp_name grad_15_small  \\\n",
    "    --task grad \\\n",
    "    --mode pathomic \\\n",
    "    --model_name pathomic_fusion \\\n",
    "    --niter 2 \\\n",
    "    --niter_decay 0 \\\n",
    "    --batch_size 4 \\\n",
    "    --lr 0.0001 \\\n",
    "    --beta1 0.5 \\\n",
    "    --fusion_type pofusion \\\n",
    "    --mmhid 32 \\\n",
    "    --use_bilinear 1 \\\n",
    "    --use_vgg_features 1 \\\n",
    "    --gpu_ids -1 \\\n",
    "    --path_gate 1 \\\n",
    "    --omic_gate 1 \\\n",
    "    --omic_scale 2 \\\n",
    "    --act LSM \\\n",
    "    --label_dim 3 \\\n",
    "    --path_dim 32 \\\n",
    "    --reg_type none\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc95713-a1c6-41a0-9b7f-3bb599ec2dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pkl_path = \"./data/TCGA_GBMLGG/splits/gbmlgg15cv_all_st_patches_512_0_0_1.pkl\"\n",
    "data_cv = pickle.load(open(pkl_path, \"rb\"))\n",
    "cv_splits = data_cv[\"cv_splits\"]\n",
    "\n",
    "fold1 = cv_splits[1]\n",
    "names = fold1[\"train\"][\"x_patname\"]\n",
    "\n",
    "print(\"Example x_patname (first 10):\")\n",
    "for n in names[:10]:\n",
    "    print(n, \"len =\", len(n))\n",
    "\n",
    "print(\"\\nCompass index example (first 10):\")\n",
    "import pandas as pd\n",
    "compass = pd.read_csv(\"./data/TCGA_GBMLGG/compass_GMBLGG.csv\")\n",
    "if \"TCGA ID\" in compass.columns:\n",
    "    compass = compass.set_index(\"TCGA ID\")\n",
    "elif \"TCGA_ID\" in compass.columns:\n",
    "    compass = compass.set_index(\"TCGA_ID\")\n",
    "\n",
    "for n in compass.index[:10]:\n",
    "    print(n, \"len =\", len(n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b097e-11fa-4986-b88c-2079488e4b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check id of embedding file and the data in pickle file \n",
    "\n",
    "pkl_path = \"./data/TCGA_GBMLGG/splits/gbmlgg15cv_all_st_0_0_0.pkl\"\n",
    "data_cv = pickle.load(open(pkl_path, \"rb\"))\n",
    "cv_splits = data_cv[\"cv_splits\"]\n",
    "\n",
    "\n",
    "all_tcga_ids = set()\n",
    "for k, fold in cv_splits.items():\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        all_tcga_ids.update(fold[split][\"x_patname\"])\n",
    "\n",
    "print(\"Total unique TCGA IDs in GBMLGG splits:\", len(all_tcga_ids))\n",
    "print(\"Example from splits:\", list(all_tcga_ids)[:10])\n",
    "\n",
    "\n",
    "compass = pd.read_csv(\"./data/TCGA_GBMLGG/compass_GMBLGG.csv\")\n",
    "\n",
    "if \"TCGA ID\" in compass.columns:\n",
    "    compass_ids = compass[\"TCGA ID\"].astype(str)\n",
    "elif \"TCGA_ID\" in compass.columns:\n",
    "    compass_ids = compass[\"TCGA_ID\"].astype(str)\n",
    "else:\n",
    "    compass_ids = compass.index.to_series().astype(str)\n",
    "\n",
    "\n",
    "compass_core_ids = set(compass_ids.str[:12].tolist())\n",
    "\n",
    "print(\"Total unique core IDs in COMPASS:\", len(compass_core_ids))\n",
    "print(\"Example from COMPASS core IDs:\", list(compass_core_ids)[:10])\n",
    "\n",
    "\n",
    "overlap = all_tcga_ids & compass_core_ids\n",
    "print(\"\\nIntersection size:\", len(overlap))\n",
    "print(\"Example intersection IDs:\", list(overlap)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9afa4b-9a36-4796-b2d0-ca5ecc618265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pkl_path = \"./data/TCGA_GBMLGG/splits/gbmlgg15cv_all_st_patches_512_0_0_1.pkl\"\n",
    "data_cv = pickle.load(open(pkl_path, \"rb\"))\n",
    "cv_splits = data_cv[\"cv_splits\"]\n",
    "\n",
    "\n",
    "all_tcga_ids = set()\n",
    "for k, fold in cv_splits.items():\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        all_tcga_ids.update(fold[split][\"x_patname\"])\n",
    "\n",
    "print(\"Total unique TCGA IDs in GBMLGG splits:\", len(all_tcga_ids))\n",
    "print(\"Example from splits:\", list(all_tcga_ids)[:10])\n",
    "\n",
    "\n",
    "compass = pd.read_csv(\"./data/TCGA_GBMLGG/compass_GMBLGG.csv\")\n",
    "\n",
    "if \"TCGA ID\" in compass.columns:\n",
    "    compass_ids = compass[\"TCGA ID\"].astype(str)\n",
    "elif \"TCGA_ID\" in compass.columns:\n",
    "    compass_ids = compass[\"TCGA_ID\"].astype(str)\n",
    "else:\n",
    "    compass_ids = compass.index.to_series().astype(str)\n",
    "\n",
    "\n",
    "compass_core_ids = set(compass_ids.str[:12].tolist())\n",
    "\n",
    "print(\"Total unique core IDs in COMPASS:\", len(compass_core_ids))\n",
    "print(\"Example from COMPASS core IDs:\", list(compass_core_ids)[:10])\n",
    "\n",
    "\n",
    "overlap = all_tcga_ids & compass_core_ids\n",
    "print(\"\\nIntersection size:\", len(overlap))\n",
    "print(\"Example intersection IDs:\", list(overlap)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f464d1-3509-47e2-b691-df0f5f060727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.read_csv(\"data/TCGA_GBMLGG/compass_GMBLGG.csv\",index_col=False)\n",
    "#value_counts('TCGA ID').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c44c2-5c0c-41c9-91fe-b66e0bc555cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pkl_path = \"./data/TCGA_GBMLGG/splits/gbmlgg15cv_all_st_patches_512_0_0_1_compass.pkl\"\n",
    "\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06ab1ce-d1dd-4676-a505-b461d2769855",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fold = list(data[\"cv_splits\"].keys())[0]\n",
    "data_fold = data[\"cv_splits\"][fold]\n",
    "list(data_fold.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d35b2d-1453-4036-a681-202b8ca725b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_omic_train = data_fold[\"train\"][\"x_omic\"]\n",
    "X_omic_test  = data_fold[\"test\"][\"x_omic\"]\n",
    "\n",
    "print(\"train count:\", len(X_omic_train))\n",
    "print(\"test count:\", len(X_omic_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa07599-6523-4686-b2de-f24175ae6252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#replace the omics in gbmlgg15cv_all_st_0_0_0.pkl to the compass embedding\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "dataroot = \"./data/TCGA_GBMLGG\"\n",
    "\n",
    "\n",
    "orig_pkl_path    = os.path.join(dataroot, \"splits\", \"gbmlgg15cv_all_st_0_0_0.pkl\")\n",
    "compass_csv_path = os.path.join(dataroot, \"compass_GMBLGG.csv\")\n",
    "\n",
    "\n",
    "out_pkl_path     = os.path.join(dataroot, \"splits\", \"gbmlgg15cv_all_st_COMPASS12_nogradem1.pkl\")\n",
    "\n",
    "\n",
    "with open(orig_pkl_path, \"rb\") as f:\n",
    "    data_cv = pickle.load(f)\n",
    "\n",
    "cv_splits = data_cv[\"cv_splits\"]\n",
    "print(\"Loaded original splits from:\", orig_pkl_path)\n",
    "print(\"Folds:\", list(cv_splits.keys()))\n",
    "\n",
    "\n",
    "compass_df = pd.read_csv(compass_csv_path)\n",
    "print(\"\\nRaw compass_df shape:\", compass_df.shape)\n",
    "print(\"Raw columns (first 5):\", compass_df.columns[:5].tolist())\n",
    "\n",
    "\n",
    "if \"Unnamed: 0\" in compass_df.columns:\n",
    "    compass_df = compass_df.drop(columns=[\"Unnamed: 0\"])\n",
    "    print(\"Dropped 'Unnamed: 0', new compass_df shape:\", compass_df.shape)\n",
    "\n",
    "\n",
    "if \"TCGA ID\" in compass_df.columns:\n",
    "    compass_df = compass_df.set_index(\"TCGA ID\")\n",
    "elif \"TCGA_ID\" in compass_df.columns:\n",
    "    compass_df = compass_df.set_index(\"TCGA_ID\")\n",
    "\n",
    "print(\"After set_index, compass_df shape:\", compass_df.shape)\n",
    "print(\"Example COMPASS index:\", compass_df.index[:5].tolist())\n",
    "\n",
    "\n",
    "compass_df = compass_df.copy()\n",
    "compass_df[\"core_id\"] = compass_df.index.to_series().astype(str).str[:12]\n",
    "compass_core = compass_df.set_index(\"core_id\")\n",
    "print(\"Compass by core_id shape:\", compass_core.shape)\n",
    "print(\"Example compass core IDs:\", compass_core.index[:5].tolist())\n",
    "\n",
    "D = compass_core.shape[1]  \n",
    "print(\"COMPASS embedding dim D =\", D)\n",
    "\n",
    "\n",
    "for k, fold in cv_splits.items():\n",
    "    print(f\"\\n===== Processing fold {k} =====\")\n",
    "\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        names = np.array(fold[split][\"x_patname\"])  '\n",
    "        g     = np.array(fold[split][\"g\"], dtype=float)\n",
    "\n",
    "        \n",
    "        names_core = np.array([str(pid)[:12] for pid in names])\n",
    "\n",
    "       \n",
    "        mask_compass = np.isin(names_core, compass_core.index)\n",
    "       \n",
    "        mask_grade   = (g != -1)\n",
    "        \n",
    "        final_mask   = mask_compass & mask_grade\n",
    "\n",
    "        print(f\"  {split}: keep {final_mask.sum()}/{len(final_mask)} \"\n",
    "              f\"(has COMPASS & grade != -1)\")\n",
    "\n",
    "        if final_mask.sum() == 0:\n",
    "            print(f\"  [Warning] fold {k} {split} has 0 valid samples, making empty split.\")\n",
    "            \n",
    "            fold[split][\"x_patname\"] = []\n",
    "           \n",
    "            x_path0 = np.array(fold[split][\"x_path\"][0])\n",
    "            fold[split][\"x_path\"] = np.empty((0,) + x_path0.shape, dtype=x_path0.dtype)\n",
    "            fold[split][\"x_grph\"] = []\n",
    "            fold[split][\"e\"] = np.array([])\n",
    "            fold[split][\"t\"] = np.array([])\n",
    "            fold[split][\"g\"] = np.array([])\n",
    "            fold[split][\"x_omic\"] = np.zeros((0, D), dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        \n",
    "        names_kept      = names[final_mask]\n",
    "        names_core_kept = names_core[final_mask]\n",
    "\n",
    "        fold[split][\"x_patname\"] = list(names_kept)\n",
    "        fold[split][\"x_path\"]    = np.array(fold[split][\"x_path\"])[final_mask]\n",
    "        fold[split][\"x_grph\"]    = [g_ for g_, m in zip(fold[split][\"x_grph\"], final_mask) if m]\n",
    "        fold[split][\"e\"]         = np.array(fold[split][\"e\"])[final_mask]\n",
    "        fold[split][\"t\"]         = np.array(fold[split][\"t\"])[final_mask]\n",
    "        fold[split][\"g\"]         = np.array(fold[split][\"g\"])[final_mask]\n",
    "\n",
    "        \n",
    "        X_omic = compass_core.loc[names_core_kept].values.astype(np.float32)  # (N_split, D)\n",
    "        fold[split][\"x_omic\"] = X_omic\n",
    "\n",
    "    \n",
    "    train_omic = fold[\"train\"].get(\"x_omic\", None)\n",
    "    if isinstance(train_omic, np.ndarray) and train_omic.shape[0] > 0:\n",
    "        scaler = StandardScaler().fit(train_omic)\n",
    "        fold[\"train\"][\"x_omic\"] = scaler.transform(train_omic)\n",
    "\n",
    "        test_omic = fold[\"test\"].get(\"x_omic\", None)\n",
    "        if isinstance(test_omic, np.ndarray) and test_omic.shape[0] > 0:\n",
    "            fold[\"test\"][\"x_omic\"] = scaler.transform(test_omic)\n",
    "    else:\n",
    "        print(f\"  [Warning] fold {k} has no valid train x_omic, skip scaling.\")\n",
    "\n",
    "\n",
    "data_cv[\"cv_splits\"] = cv_splits\n",
    "\n",
    "with open(out_pkl_path, \"wb\") as f:\n",
    "    pickle.dump(data_cv, f)\n",
    "\n",
    "print(\"\\nSaved clean COMPASS+no(-1) splits to:\", out_pkl_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d36c5c5-2367-46e2-ba53-d6956bbcee8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "dataroot = \"./data/TCGA_GBMLGG\"\n",
    "\n",
    "\n",
    "orig_pkl_path    = os.path.join(dataroot, \"splits\", \"gbmlgg15cv_all_st_patches_512_0_0_1.pkl\")\n",
    "compass_csv_path = os.path.join(dataroot, \"compass_GMBLGG.csv\")\n",
    "\n",
    "\n",
    "out_pkl_path     = os.path.join(dataroot, \"splits\", \"gbmlgg15cv_all_st_patches_512_0_0_1_compass.pkl\")\n",
    "\n",
    "\n",
    "with open(orig_pkl_path, \"rb\") as f:\n",
    "    data_cv = pickle.load(f)\n",
    "\n",
    "cv_splits = data_cv[\"cv_splits\"]\n",
    "print(\"Loaded original splits from:\", orig_pkl_path)\n",
    "print(\"Folds:\", list(cv_splits.keys()))\n",
    "\n",
    "\n",
    "compass_df = pd.read_csv(compass_csv_path)\n",
    "print(\"\\nRaw compass_df shape:\", compass_df.shape)\n",
    "print(\"Raw columns (first 5):\", compass_df.columns[:5].tolist())\n",
    "\n",
    "\n",
    "if \"Unnamed: 0\" in compass_df.columns:\n",
    "    compass_df = compass_df.drop(columns=[\"Unnamed: 0\"])\n",
    "    print(\"Dropped 'Unnamed: 0', new compass_df shape:\", compass_df.shape)\n",
    "\n",
    "\n",
    "if \"TCGA ID\" in compass_df.columns:\n",
    "    compass_df = compass_df.set_index(\"TCGA ID\")\n",
    "elif \"TCGA_ID\" in compass_df.columns:\n",
    "    compass_df = compass_df.set_index(\"TCGA_ID\")\n",
    "\n",
    "print(\"After set_index, compass_df shape:\", compass_df.shape)\n",
    "print(\"Example COMPASS index:\", compass_df.index[:5].tolist())\n",
    "\n",
    "\n",
    "compass_df = compass_df.copy()\n",
    "compass_df[\"core_id\"] = compass_df.index.to_series().astype(str).str[:12]\n",
    "compass_core = compass_df.set_index(\"core_id\")\n",
    "print(\"Compass by core_id shape:\", compass_core.shape)\n",
    "print(\"Example compass core IDs:\", compass_core.index[:5].tolist())\n",
    "\n",
    "D = compass_core.shape[1]  \n",
    "print(\"COMPASS embedding dim D =\", D)\n",
    "\n",
    "\n",
    "for k, fold in cv_splits.items():\n",
    "    print(f\"\\n===== Processing fold {k} =====\")\n",
    "\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        names = np.array(fold[split][\"x_patname\"])  \n",
    "        g     = np.array(fold[split][\"g\"], dtype=float)\n",
    "\n",
    "        \n",
    "        names_core = np.array([str(pid)[:12] for pid in names])\n",
    "\n",
    "       \n",
    "        mask_compass = np.isin(names_core, compass_core.index)\n",
    "       \n",
    "        mask_grade   = (g != -1)\n",
    "        \n",
    "        final_mask   = mask_compass & mask_grade\n",
    "\n",
    "        print(f\"  {split}: keep {final_mask.sum()}/{len(final_mask)} \"\n",
    "              f\"(has COMPASS & grade != -1)\")\n",
    "\n",
    "        if final_mask.sum() == 0:\n",
    "            print(f\"  [Warning] fold {k} {split} has 0 valid samples, making empty split.\")\n",
    "            \n",
    "            fold[split][\"x_patname\"] = []\n",
    "           \n",
    "            x_path0 = np.array(fold[split][\"x_path\"][0])\n",
    "            fold[split][\"x_path\"] = np.empty((0,) + x_path0.shape, dtype=x_path0.dtype)\n",
    "            fold[split][\"x_grph\"] = []\n",
    "            fold[split][\"e\"] = np.array([])\n",
    "            fold[split][\"t\"] = np.array([])\n",
    "            fold[split][\"g\"] = np.array([])\n",
    "            fold[split][\"x_omic\"] = np.zeros((0, D), dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        \n",
    "        names_kept      = names[final_mask]\n",
    "        names_core_kept = names_core[final_mask]\n",
    "\n",
    "        fold[split][\"x_patname\"] = list(names_kept)\n",
    "        fold[split][\"x_path\"]    = np.array(fold[split][\"x_path\"])[final_mask]\n",
    "        fold[split][\"x_grph\"]    = [g_ for g_, m in zip(fold[split][\"x_grph\"], final_mask) if m]\n",
    "        fold[split][\"e\"]         = np.array(fold[split][\"e\"])[final_mask]\n",
    "        fold[split][\"t\"]         = np.array(fold[split][\"t\"])[final_mask]\n",
    "        fold[split][\"g\"]         = np.array(fold[split][\"g\"])[final_mask]\n",
    "\n",
    "        \n",
    "        X_omic = compass_core.loc[names_core_kept].values.astype(np.float32)  # (N_split, D)\n",
    "        fold[split][\"x_omic\"] = X_omic\n",
    "\n",
    "    \n",
    "    train_omic = fold[\"train\"].get(\"x_omic\", None)\n",
    "    if isinstance(train_omic, np.ndarray) and train_omic.shape[0] > 0:\n",
    "        scaler = StandardScaler().fit(train_omic)\n",
    "        fold[\"train\"][\"x_omic\"] = scaler.transform(train_omic)\n",
    "\n",
    "        test_omic = fold[\"test\"].get(\"x_omic\", None)\n",
    "        if isinstance(test_omic, np.ndarray) and test_omic.shape[0] > 0:\n",
    "            fold[\"test\"][\"x_omic\"] = scaler.transform(test_omic)\n",
    "    else:\n",
    "        print(f\"  [Warning] fold {k} has no valid train x_omic, skip scaling.\")\n",
    "\n",
    "\n",
    "data_cv[\"cv_splits\"] = cv_splits\n",
    "\n",
    "with open(out_pkl_path, \"wb\") as f:\n",
    "    pickle.dump(data_cv, f)\n",
    "\n",
    "print(\"\\nSaved clean COMPASS+no(-1) splits to:\", out_pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b29341-c4fd-4257-b4e3-830625f88896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "dataroot = \"./data/TCGA_GBMLGG\"\n",
    "\n",
    "\n",
    "orig_pkl_path    = os.path.join(dataroot, \"splits\", \"gbmlgg15cv_all_st_patches_512_0_1_1.pkl\")\n",
    "compass_csv_path = os.path.join(dataroot, \"compass_GMBLGG.csv\")\n",
    "\n",
    "\n",
    "out_pkl_path     = os.path.join(dataroot, \"splits\", \"gbmlgg15cv_all_st_patches_512_0_1_1_compass.pkl\")\n",
    "\n",
    "\n",
    "with open(orig_pkl_path, \"rb\") as f:\n",
    "    data_cv = pickle.load(f)\n",
    "\n",
    "cv_splits = data_cv[\"cv_splits\"]\n",
    "print(\"Loaded original splits from:\", orig_pkl_path)\n",
    "print(\"Folds:\", list(cv_splits.keys()))\n",
    "\n",
    "\n",
    "compass_df = pd.read_csv(compass_csv_path)\n",
    "print(\"\\nRaw compass_df shape:\", compass_df.shape)\n",
    "print(\"Raw columns (first 5):\", compass_df.columns[:5].tolist())\n",
    "\n",
    "\n",
    "if \"Unnamed: 0\" in compass_df.columns:\n",
    "    compass_df = compass_df.drop(columns=[\"Unnamed: 0\"])\n",
    "    print(\"Dropped 'Unnamed: 0', new compass_df shape:\", compass_df.shape)\n",
    "\n",
    "\n",
    "if \"TCGA ID\" in compass_df.columns:\n",
    "    compass_df = compass_df.set_index(\"TCGA ID\")\n",
    "elif \"TCGA_ID\" in compass_df.columns:\n",
    "    compass_df = compass_df.set_index(\"TCGA_ID\")\n",
    "\n",
    "print(\"After set_index, compass_df shape:\", compass_df.shape)\n",
    "print(\"Example COMPASS index:\", compass_df.index[:5].tolist())\n",
    "\n",
    "\n",
    "compass_df = compass_df.copy()\n",
    "compass_df[\"core_id\"] = compass_df.index.to_series().astype(str).str[:12]\n",
    "compass_core = compass_df.set_index(\"core_id\")\n",
    "print(\"Compass by core_id shape:\", compass_core.shape)\n",
    "print(\"Example compass core IDs:\", compass_core.index[:5].tolist())\n",
    "\n",
    "D = compass_core.shape[1]  \n",
    "print(\"COMPASS embedding dim D =\", D)\n",
    "\n",
    "\n",
    "for k, fold in cv_splits.items():\n",
    "    print(f\"\\n===== Processing fold {k} =====\")\n",
    "\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        names = np.array(fold[split][\"x_patname\"])  \n",
    "        g     = np.array(fold[split][\"g\"], dtype=float)\n",
    "\n",
    "        \n",
    "        names_core = np.array([str(pid)[:12] for pid in names])\n",
    "\n",
    "       \n",
    "        mask_compass = np.isin(names_core, compass_core.index)\n",
    "       \n",
    "        mask_grade   = (g != -1)\n",
    "        \n",
    "        final_mask   = mask_compass & mask_grade\n",
    "\n",
    "        print(f\"  {split}: keep {final_mask.sum()}/{len(final_mask)} \"\n",
    "              f\"(has COMPASS & grade != -1)\")\n",
    "\n",
    "        if final_mask.sum() == 0:\n",
    "            print(f\"  [Warning] fold {k} {split} has 0 valid samples, making empty split.\")\n",
    "            \n",
    "            fold[split][\"x_patname\"] = []\n",
    "           \n",
    "            x_path0 = np.array(fold[split][\"x_path\"][0])\n",
    "            fold[split][\"x_path\"] = np.empty((0,) + x_path0.shape, dtype=x_path0.dtype)\n",
    "            fold[split][\"x_grph\"] = []\n",
    "            fold[split][\"e\"] = np.array([])\n",
    "            fold[split][\"t\"] = np.array([])\n",
    "            fold[split][\"g\"] = np.array([])\n",
    "            fold[split][\"x_omic\"] = np.zeros((0, D), dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        \n",
    "        names_kept      = names[final_mask]\n",
    "        names_core_kept = names_core[final_mask]\n",
    "\n",
    "        fold[split][\"x_patname\"] = list(names_kept)\n",
    "        fold[split][\"x_path\"]    = np.array(fold[split][\"x_path\"])[final_mask]\n",
    "        fold[split][\"x_grph\"]    = [g_ for g_, m in zip(fold[split][\"x_grph\"], final_mask) if m]\n",
    "        fold[split][\"e\"]         = np.array(fold[split][\"e\"])[final_mask]\n",
    "        fold[split][\"t\"]         = np.array(fold[split][\"t\"])[final_mask]\n",
    "        fold[split][\"g\"]         = np.array(fold[split][\"g\"])[final_mask]\n",
    "\n",
    "        \n",
    "        X_omic = compass_core.loc[names_core_kept].values.astype(np.float32)  # (N_split, D)\n",
    "        fold[split][\"x_omic\"] = X_omic\n",
    "\n",
    "    \n",
    "    train_omic = fold[\"train\"].get(\"x_omic\", None)\n",
    "    if isinstance(train_omic, np.ndarray) and train_omic.shape[0] > 0:\n",
    "        scaler = StandardScaler().fit(train_omic)\n",
    "        fold[\"train\"][\"x_omic\"] = scaler.transform(train_omic)\n",
    "\n",
    "        test_omic = fold[\"test\"].get(\"x_omic\", None)\n",
    "        if isinstance(test_omic, np.ndarray) and test_omic.shape[0] > 0:\n",
    "            fold[\"test\"][\"x_omic\"] = scaler.transform(test_omic)\n",
    "    else:\n",
    "        print(f\"  [Warning] fold {k} has no valid train x_omic, skip scaling.\")\n",
    "\n",
    "\n",
    "data_cv[\"cv_splits\"] = cv_splits\n",
    "\n",
    "with open(out_pkl_path, \"wb\") as f:\n",
    "    pickle.dump(data_cv, f)\n",
    "\n",
    "print(\"\\nSaved clean COMPASS+no(-1) splits to:\", out_pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef1e58-9a25-44ff-9483-92a9e14300d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pkl_path_orig = \"./data/TCGA_GBMLGG/splits/gbmlgg15cv_all_st_patches_512_0_0_0.pkl\"\n",
    "pkl_path_comp = \"./data/TCGA_GBMLGG/splits/gbmlgg15cv_all_st_patches_512_0_0_0_compass.pkl\"\n",
    "\n",
    "with open(pkl_path_orig, \"rb\") as f:\n",
    "    orig = pickle.load(f)\n",
    "with open(pkl_path_comp, \"rb\") as f:\n",
    "    comp = pickle.load(f)\n",
    "\n",
    "orig_pd = orig[\"data_pd\"]\n",
    "comp_pd = comp[\"data_pd\"]\n",
    "\n",
    "print(\"orig columns:\", orig_pd.columns)\n",
    "print(\"comp columns:\", comp_pd.columns)\n",
    "\n",
    "print(\"\\norig dtypes:\")\n",
    "print(orig_pd.dtypes)\n",
    "print(\"\\ncomp dtypes:\")\n",
    "print(comp_pd.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbec003-9a6d-4ee7-801d-3b792c61dd2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test if the new compass pickle input works on omicnet\n",
    "\n",
    "\n",
    "!\"{sys.executable}\" train_cv.py \\\n",
    "  --exp_name grad_compass_omic \\\n",
    "  --task grad \\\n",
    "  --mode omic \\\n",
    "  --model_name omic \\\n",
    "  --input_size_omic 1376 \\\n",
    "  --niter 2 \\\n",
    "  --niter_decay 0 \\\n",
    "  --batch_size 64 \\\n",
    "  --lr 0.002 \\\n",
    "  --reg_type none \\\n",
    "  --init_type max \\\n",
    "  --weight_decay 5e-4 \\\n",
    "  --act LSM \\\n",
    "  --label_dim 3 \\\n",
    "  --gpu_ids -1 \\\n",
    "  --use_rnaseq 0 \\\n",
    "  --verbose 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e3a358-f195-4fd9-b441-8466488d9de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test if the new compass pickle input works on  pathomic\n",
    "\n",
    "\n",
    "!\"{sys.executable}\" train_cv.py \\\n",
    "  --exp_name grad_compass_omic \\\n",
    "  --task surv \\\n",
    " --mode pathomic \\\n",
    "  --model_name pathomic_fusion \\\n",
    "  --niter 2 \\\n",
    "  --niter_decay 0 \\\n",
    "  --batch_size 8 \\\n",
    "  --lr 0.0001 \\\n",
    "  --beta1 0.5 \\\n",
    "  --reg_type none \\\n",
    "  --fusion_type pofusion \\\n",
    "  --mmhid 64 \\\n",
    "  --use_bilinear 0 \\\n",
    "  --use_vgg_features 1 \\\n",
    "  --gpu_ids -1 \\\n",
    "  --omic_gate 0 \\\n",
    "  --use_rnaseq 1 \\\n",
    "  --input_size_omic 1376 \\\n",
    "  --path_dim 32\\\n",
    "  --finetune 1 \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ea08d-bc4c-4004-a62a-94b1861ab038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "!\"{sys.executable}\" train_cv.py \\\n",
    "  --exp_name surv_compass_omic_gates \\\n",
    "  --task surv \\\n",
    " --mode pathomic \\\n",
    "  --model_name pathomic_fusion \\\n",
    "  --niter 2 \\\n",
    "  --niter_decay 0 \\\n",
    "  --batch_size 8 \\\n",
    "  --lr 0.0001 \\\n",
    "  --beta1 0.5 \\\n",
    "  --reg_type none \\\n",
    "  --fusion_type pofusion \\\n",
    "  --mmhid 64 \\\n",
    "  --use_bilinear 0 \\\n",
    "  --use_vgg_features 1 \\\n",
    "  --gpu_ids -1 \\\n",
    "  --omic_gate 0 \\\n",
    "  --use_rnaseq 1 \\\n",
    "  --input_size_omic 1376 \\\n",
    "  --path_dim 32\\\n",
    "  --finetune 1 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac3d9c-20a4-45fb-94d5-dba1fb9dac7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train with 2 epochs \n",
    "\n",
    "!\"{sys.executable}\" train_cv.py \\\n",
    "  --exp_name surv_compass_omic_gates_bi\\\n",
    "  --task surv \\\n",
    " --mode pathomic \\\n",
    "  --model_name pathomic_fusion \\\n",
    "  --niter 2 \\\n",
    "  --niter_decay 0 \\\n",
    "  --batch_size 8 \\\n",
    "  --lr 0.0001 \\\n",
    "  --beta1 0.5 \\\n",
    "  --reg_type none \\\n",
    "  --fusion_type pofusion \\\n",
    "  --mmhid 64 \\\n",
    "  --use_bilinear 1 \\\n",
    "  --use_vgg_features 1 \\\n",
    "  --gpu_ids -1 \\\n",
    "  --omic_gate 0 \\\n",
    "  --use_rnaseq 1 \\\n",
    "  --input_size_omic 1376 \\\n",
    "  --path_dim 32\\\n",
    "  --finetune 1 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd4e32-0f0b-420e-b976-6434cf35ca03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train with 10 epochs ,lr 0.00005\n",
    "\n",
    "import sys\n",
    "\n",
    "!\"{sys.executable}\" train_cv.py \\\n",
    "  --exp_name surv_compass_omic_gates_bi_ff_ver2\\\n",
    "  --task surv \\\n",
    " --mode pathomic \\\n",
    "  --model_name pathomic_fusion \\\n",
    "  --niter 5 \\\n",
    "  --niter_decay 5 \\\n",
    "  --batch_size 8 \\\n",
    "  --lr 0.00005 \\\n",
    "  --beta1 0.5 \\\n",
    "  --reg_type none \\\n",
    "  --fusion_type pofusion \\\n",
    "  --mmhid 64 \\\n",
    "  --use_bilinear 1 \\\n",
    "  --use_vgg_features 1 \\\n",
    "  --gpu_ids -1 \\\n",
    "  --omic_gate 0 \\\n",
    "  --use_rnaseq 1 \\\n",
    "  --input_size_omic 1376 \\\n",
    "  --path_dim 32\\\n",
    "  --finetune 0 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78686085-54df-4cc0-bcac-ca4c83d3b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train with 10 epochs ,lr 0.0001\n",
    "\n",
    "\n",
    "!\"{sys.executable}\" train_cv.py \\\n",
    "  --exp_name surv_compass_omic_gates_bi_ff\\\n",
    "  --task surv \\\n",
    " --mode pathomic \\\n",
    "  --model_name pathomic_fusion \\\n",
    "  --niter 5 \\\n",
    "  --niter_decay 5 \\\n",
    "  --batch_size 8 \\\n",
    "  --lr 0.0001 \\\n",
    "  --beta1 0.5 \\\n",
    "  --reg_type none \\\n",
    "  --fusion_type pofusion \\\n",
    "  --mmhid 64 \\\n",
    "  --use_bilinear 1 \\\n",
    "  --use_vgg_features 1 \\\n",
    "  --gpu_ids -1 \\\n",
    "  --omic_gate 0 \\\n",
    "  --use_rnaseq 1 \\\n",
    "  --input_size_omic 1376 \\\n",
    "  --path_dim 32\\\n",
    "  --finetune 0 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf1c46-f5a6-4c30-a3bd-fce2d11c41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "!\"{sys.executable}\" train_cv.py \\\n",
    "  --exp_name surv_compass_pgo_gates \\\n",
    "  --task surv \\\n",
    " --mode pathgraphomic \\\n",
    "  --model_name pathgraphomic_fusion \\\n",
    "  --niter 2 \\\n",
    "  --niter_decay 0 \\\n",
    "  --batch_size 8 \\\n",
    "  --lr 0.0001 \\\n",
    "  --beta1 0.5 \\\n",
    "  --reg_type none \\\n",
    "  --fusion_type pofusion_A \\\n",
    "  --mmhid 64 \\\n",
    "  --use_bilinear 1 \\\n",
    "  --use_vgg_features 1 \\\n",
    "  --gpu_ids -1 \\\n",
    "  --omic_gate 0 \\\n",
    "  --use_rnaseq 1 \\\n",
    "  --input_size_omic 1376 \\\n",
    "  --path_dim 32\\\n",
    "  --finetune 1 \\\n",
    "  --grph_scale 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdcdf73-8c57-4644-95d0-8565f78e71ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "##network changed (replace SNN with compass embedding that have already be placed  in the input pickle file using above vode)\n",
    "#changed from Pathomic Fsusion network.py\n",
    "#if want to use, need to paste this back to the network.py file of the pathomic fusion before run the training command\n",
    "#also need to edit the train_test.py if want to store the gate activation as pickle file \n",
    "##############################################################################\n",
    "# Path + Omic\n",
    "##############################################################################\n",
    "class PathomicNet(nn.Module):\n",
    "    def __init__(self, opt, act, k): \n",
    "        super(PathomicNet, self).__init__() \n",
    "        self.path_dim = opt.path_dim \n",
    "        self.omic_dim = opt.omic_dim \n",
    "        \n",
    "        #####change here \n",
    "        #self.path_encoder = resnet50(pretrained=True) \n",
    "        self.omic_proj = nn.Linear(opt.input_size_omic, opt.omic_dim) \n",
    "        hidden_dim = 64 \n",
    "        self.gate_mlp = nn.Sequential( nn.Linear(self.path_dim + self.omic_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, self.path_dim), nn.Sigmoid() ) \n",
    "       \n",
    "        self.fusion = define_bifusion(fusion_type=opt.fusion_type, skip=opt.skip, use_bilinear=opt.use_bilinear, gate1=opt.path_gate, gate2=opt.omic_gate, dim1=opt.path_dim, dim2=opt.omic_dim, scale_dim1=opt.path_scale, scale_dim2=opt.omic_scale, mmhid=opt.mmhid, dropout_rate=opt.dropout_rate) self.classifier = nn.Sequential(nn.Linear(opt.mmhid, opt.label_dim)) \n",
    "        self.act = act \n",
    "        #####change here \n",
    "        #dfs_freeze(self.omic_net) \n",
    "        self.output_range = Parameter(torch.FloatTensor([6]), requires_grad=False) \n",
    "        self.output_shift = Parameter(torch.FloatTensor([-3]), requires_grad=False)\n",
    "        \n",
    "        \n",
    "        def forward(self, **kwargs): \n",
    "            path_vec = kwargs['x_path'] \n",
    "            \n",
    "            x_omic = kwargs['x_omic'] \n",
    "            omic_vec = self.omic_proj(x_omic) \n",
    "            \n",
    "            concat = torch.cat([path_vec, omic_vec], dim=1) \n",
    "            gate = self.gate_mlp(concat) \n",
    "            gated_path = gate * path_vec \n",
    "            \n",
    "            self.last_gate = gate \n",
    "            features = self.fusion(gated_path, omic_vec) \n",
    "            hazard = self.classifier(features) \n",
    "            if self.act is not None: \n",
    "                hazard = self.act(hazard) \n",
    "                if isinstance(self.act, nn.Sigmoid): \n",
    "                    hazard = hazard * self.output_range + self.output_shift \n",
    "            return features, hazard\n",
    "\n",
    "\n",
    "    def __hasattr__(self, name):\n",
    "        if '_parameters' in self.__dict__:\n",
    "            _parameters = self.__dict__['_parameters']\n",
    "            if name in _parameters:\n",
    "                return True\n",
    "        if '_buffers' in self.__dict__:\n",
    "            _buffers = self.__dict__['_buffers']\n",
    "            if name in _buffers:\n",
    "                return True\n",
    "        if '_modules' in self.__dict__:\n",
    "            modules = self.__dict__['_modules']\n",
    "            if name in modules:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55df3da-40a8-4585-8c9e-27274aafcd84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0da02f-c313-42d0-9985-3e3524903c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a082e0d-9db9-4d35-b777-8f23e4185aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7914300-d08f-46ea-abec-5ba70fb55504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (COMPASS)",
   "language": "python",
   "name": "compass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
